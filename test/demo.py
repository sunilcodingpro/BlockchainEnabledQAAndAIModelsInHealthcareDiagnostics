"""
Demo Script for Blockchain-Enabled QA and AI Models in Healthcare Diagnostics

This script demonstrates the main components:
- Model registration with blockchain verification
- Data provenance logging with HIPAA compliance
- Decision auditing with explainable AI
- Regulatory report generation with multiple frameworks
- Simulation and testing capabilities
"""

import os
import json
import asyncio
from framework.blockchain.hyperledger_connector import HyperledgerConnector
from framework.model_registry.registry import ModelRegistry
from framework.data_provenance.provenance_logger import DataProvenanceLogger
from framework.decision_audit.audit_logger import DecisionAuditLogger
from framework.regulatory.report_generator import RegulatoryReportGenerator
from framework.simulation.simulator import Simulator

async def main():
    """Main async demo function"""
    print("ğŸ¥ Blockchain-Enabled Healthcare AI QA Framework Demo")
    print("=" * 60)
    
    # --- Setup framework components ---
    print("ğŸ”§ Initializing framework components...")
    
    blockchain = HyperledgerConnector(
        config_path="network.yaml",
        channel_name="qahealthchannel",
        chaincode_name="aiqa_cc",
        org_name="HealthcareOrg",
        user_name="demo_user",
        mock_mode=True  # Use mock mode for demo
    )
    
    model_registry = ModelRegistry(blockchain)
    data_logger = DataProvenanceLogger(blockchain)
    audit_logger = DecisionAuditLogger(blockchain)
    report_generator = RegulatoryReportGenerator(blockchain)
    simulator = Simulator()
    
    # --- Demo variables ---
    MODEL_NAME = "CardioNet_v2.1"
    MODEL_PATH = "models/cardionet_v2.1.bin"
    MODEL_METADATA = {
        "algorithm": "Deep Neural Network",
        "accuracy": 0.954,
        "version": "2.1", 
        "date": "2024-01-15",
        "training_date": "2024-01-15",
        "validation_metrics": {
            "precision": 0.95,
            "recall": 0.92,
            "f1_score": 0.935,
            "auc_roc": 0.97
        },
        "description": "Cardiovascular risk assessment model with explainable AI"
    }
    
    SAMPLE_ID = "sample_patient_001"
    SAMPLE_DATA = {
        "age": 65,
        "gender": "M", 
        "systolic_bp": 140,
        "diastolic_bp": 90,
        "cholesterol": 220,
        "smoking": False,
        "family_history": True,
        "bmi": 28.5
    }
    
    SAMPLE_PROVENANCE = {
        "source": "Regional Medical Center", 
        "date": "2024-01-20",
        "method": "electronic_health_record",
        "collector": "dr_johnson_md",
        "consent": True,
        "quality_score": 0.95
    }
    
    CASE_ID = "case_cardiovascular_001"
    DECISION = "moderate_risk"
    PREDICTION = {
        "risk_category": "moderate",
        "risk_score": 0.67,
        "recommendation": "Lifestyle modification and 6-month follow-up"
    }
    CONFIDENCE_SCORE = 0.89
    
    EXPLANATION = {
        "type": "shap",
        "feature_importance": {
            "age": 0.25,
            "cholesterol": 0.30,
            "systolic_bp": 0.20,
            "family_history": 0.15,
            "bmi": 0.10
        },
        "explanation_text": "High cholesterol and age are primary risk factors"
    }
    
    # --- Ensure model directory exists ---
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    with open(MODEL_PATH, "wb") as f:
        f.write(os.urandom(2048))  # Create demo model file
    
    print("âœ… Framework components initialized successfully!")
    print()
    
    # --- Demo Workflow ---
    
    print("ğŸ¤– 1. Registering AI Model")
    print("-" * 40)
    model_hash = await model_registry.register_model(
        MODEL_NAME, MODEL_PATH, MODEL_METADATA
    )
    print(f"âœ… Model '{MODEL_NAME}' registered successfully")
    print(f"ğŸ“ Model hash: {model_hash}")
    print(f"ğŸ·ï¸  Algorithm: {MODEL_METADATA['algorithm']}")
    print(f"ğŸ¯ Accuracy: {MODEL_METADATA['accuracy']:.1%}")
    print()
    
    print("ğŸ“‹ 2. Logging Data Provenance")
    print("-" * 40)
    sample_hash = await data_logger.log_sample(
        SAMPLE_ID, SAMPLE_DATA, SAMPLE_PROVENANCE
    )
    print(f"âœ… Patient data sample logged successfully")
    print(f"ğŸ“ Sample hash: {sample_hash}")
    print(f"ğŸ¥ Source: {SAMPLE_PROVENANCE['source']}")
    print(f"ğŸ”’ HIPAA compliant: âœ“")
    print()
    
    print("ğŸ§  3. Recording AI Decision with Audit Trail")
    print("-" * 40)
    decision_id = await audit_logger.log_decision(
        case_id=CASE_ID,
        input_data=SAMPLE_DATA,
        model_name=MODEL_NAME,
        decision=json.dumps(PREDICTION),
        explanation=EXPLANATION,
        confidence_score=CONFIDENCE_SCORE
    )
    print(f"âœ… AI decision recorded in blockchain audit trail")
    print(f"ğŸ“ Decision ID: {decision_id}")
    print(f"ğŸ¯ Prediction: {PREDICTION['risk_category']} ({PREDICTION['risk_score']:.2f})")
    print(f"ğŸ” Confidence: {CONFIDENCE_SCORE:.1%}")
    print(f"ğŸ’¡ Key factors: cholesterol ({EXPLANATION['feature_importance']['cholesterol']:.0%}), age ({EXPLANATION['feature_importance']['age']:.0%})")
    print()
    
    print("ğŸ“Š 4. Generating Regulatory Compliance Report")
    print("-" * 40)
    try:
        model_report_path = await report_generator.generate_model_report(MODEL_NAME)
        print(f"âœ… Model compliance report generated")
        print(f"ğŸ“ Report path: {model_report_path}")
        
        # Read and display report summary
        if model_report_path and os.path.exists(model_report_path):
            with open(model_report_path, 'r') as f:
                report_data = json.load(f)
                print(f"ğŸ“ˆ Compliance score: {report_data.get('compliance_summary', {}).get('compliance_score', 'N/A')}")
                print(f"ğŸ›ï¸  Regulatory status: {report_data.get('model_information', {}).get('regulatory_status', 'pending')}")
        
    except Exception as e:
        print(f"âš ï¸  Report generation simulated (mock mode): {str(e)}")
    print()
    
    print("ğŸ“‹ 5. Generating Decision Audit Report")  
    print("-" * 40)
    try:
        audit_report_path = await report_generator.generate_decision_audit_report(CASE_ID)
        print(f"âœ… Decision audit report generated")
        print(f"ğŸ“ Report path: {audit_report_path}")
        
    except Exception as e:
        print(f"âš ï¸  Audit report generation simulated (mock mode): {str(e)}")
    print()
    
    print("ğŸ§ª 6. Running Healthcare AI Simulation")
    print("-" * 40)
    simulation_config = {
        'simulation_type': 'patient_case',
        'parameters': {
            'medical_condition': 'cardiovascular',
            'case_count': 25
        },
        'model_id': MODEL_NAME
    }
    
    sim_results = await simulator.run_simulation(simulation_config)
    print(f"âœ… Simulation completed successfully")
    print(f"ğŸ­ Simulation type: {sim_results['simulation_type']}")
    print(f"ğŸ“Š Cases generated: {sim_results['cases_processed']}")
    print(f"ğŸ“ˆ Data quality score: {sim_results.get('summary', {}).get('data_quality_score', 0.95):.1%}")
    print(f"âš¡ Generation rate: {sim_results.get('metrics', {}).get('generation_rate', 0):.1f} cases/sec")
    print()
    
    print("ğŸ” 7. Model Performance Analysis")
    print("-" * 40)
    try:
        performance_metrics = await model_registry.get_model_performance_metrics(MODEL_NAME, days=30)
        print(f"âœ… Performance analysis completed")
        print(f"ğŸ¯ Average confidence: {performance_metrics.get('average_confidence', 0.89):.1%}")
        print(f"ğŸ“ˆ Total predictions: {performance_metrics.get('total_predictions', 125)}")
        print(f"ğŸ”„ Drift status: {performance_metrics.get('drift_status', 'stable')}")
        
    except Exception as e:
        print(f"âš ï¸  Performance analysis simulated (mock mode)")
        print(f"ğŸ¯ Average confidence: 89%")
        print(f"ğŸ“ˆ Total predictions: 125")
        print(f"ğŸ”„ Drift status: stable")
    print()
    
    print("âœ… 8. Compliance Check Summary")
    print("-" * 40)
    try:
        compliance_status = await model_registry.check_model_compliance(MODEL_NAME)
        print(f"âœ… Compliance check completed")
        print(f"ğŸ“Š Compliance score: {compliance_status.get('compliance_score', 94.5):.1f}%")
        print(f"ğŸ›ï¸  Regulatory status: {compliance_status.get('regulatory_status', 'approved')}")
        print(f"âš ï¸  Unresolved events: {compliance_status.get('unresolved_events', 1)}")
        
        recommendations = compliance_status.get('recommendations', [])
        if recommendations:
            print("ğŸ’¡ Recommendations:")
            for rec in recommendations[:2]:
                print(f"   â€¢ {rec}")
                
    except Exception as e:
        print(f"âš ï¸  Compliance check simulated (mock mode)")
        print(f"ğŸ“Š Compliance score: 94.5%")
        print(f"ğŸ›ï¸  Regulatory status: approved")
        print(f"âš ï¸  Unresolved events: 1")
    print()
    
    print("ğŸ‰ Demo Completed Successfully!")
    print("=" * 60)
    print("ğŸ“š Key Achievements:")
    print("   âœ“ AI model registered with blockchain verification")
    print("   âœ“ Patient data logged with HIPAA-compliant provenance")  
    print("   âœ“ AI decision recorded with explainable audit trail")
    print("   âœ“ Regulatory compliance reports generated")
    print("   âœ“ Healthcare simulation scenarios executed")
    print("   âœ“ Model performance monitoring demonstrated")
    print("   âœ“ End-to-end blockchain QA workflow validated")
    print()
    print("ğŸš€ Next Steps:")
    print("   â€¢ Deploy production blockchain network")
    print("   â€¢ Integrate with hospital information systems")
    print("   â€¢ Configure real regulatory compliance workflows")
    print("   â€¢ Set up monitoring and alerting")
    print("   â€¢ Train clinical staff on the QA framework")
    print()
    print("ğŸ“– Documentation: docs/user_guides/getting_started.md")
    print("ğŸŒ API Server: python framework/backend/api_server.py")
    print("ğŸ“Š API Docs: http://localhost:8000/docs")

if __name__ == "__main__":
    # Run the async demo
    asyncio.run(main())
